{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:29:05.796437Z","iopub.status.busy":"2022-09-28T10:29:05.795597Z","iopub.status.idle":"2022-09-28T10:29:12.587823Z","shell.execute_reply":"2022-09-28T10:29:12.586828Z","shell.execute_reply.started":"2022-09-28T10:29:05.796334Z"},"id":"Q2PepmWUUlzU","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import sklearn as sk\n","\n","import tensorflow.experimental.numpy as tnp\n","tnp.experimental_enable_numpy_behavior()\n","\n","from skimage.transform import resize\n","\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Dense, Input, Flatten,\\\n","                                    Reshape, LeakyReLU as LR,\\\n","                                    Activation, Dropout, Conv2D, MaxPooling2D, Conv2DTranspose\n","from tensorflow.keras.models import Model, Sequential\n","from matplotlib import pyplot as plt\n","from IPython import display # If using IPython, Colab or Jupyter\n","import numpy as np\n","from time import time\n","\n","from numba import jit, float32, vectorize, guvectorize\n","import math\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:29:12.592008Z","iopub.status.busy":"2022-09-28T10:29:12.590071Z","iopub.status.idle":"2022-09-28T10:29:14.149687Z","shell.execute_reply":"2022-09-28T10:29:14.148029Z","shell.execute_reply.started":"2022-09-28T10:29:12.591966Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:29:14.154544Z","iopub.status.busy":"2022-09-28T10:29:14.154108Z","iopub.status.idle":"2022-09-28T10:29:16.554958Z","shell.execute_reply":"2022-09-28T10:29:16.553896Z","shell.execute_reply.started":"2022-09-28T10:29:14.154503Z"},"trusted":true},"outputs":[],"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"markdown","metadata":{"id":"rj8Ps-_oUqrG"},"source":["imporing mnist"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:29:16.558441Z","iopub.status.busy":"2022-09-28T10:29:16.557828Z","iopub.status.idle":"2022-09-28T10:29:17.531141Z","shell.execute_reply":"2022-09-28T10:29:17.530130Z","shell.execute_reply.started":"2022-09-28T10:29:16.558406Z"},"id":"5wM-J2qfUsQE","trusted":true},"outputs":[],"source":["# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train = (x_train/256-0.5).astype('float32') \n","x_test = (x_test/256-0.5).astype('float32') "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:36.979924Z","iopub.status.busy":"2022-09-28T10:30:36.979560Z","iopub.status.idle":"2022-09-28T10:30:36.984459Z","shell.execute_reply":"2022-09-28T10:30:36.983295Z","shell.execute_reply.started":"2022-09-28T10:30:36.979895Z"},"id":"ZWZCMLaw6u_p","trusted":true},"outputs":[],"source":["x_train = x_train#[y_train == 2]\n","x_test = x_test#[y_test == 2]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:37.234046Z","iopub.status.busy":"2022-09-28T10:30:37.233346Z","iopub.status.idle":"2022-09-28T10:30:37.238528Z","shell.execute_reply":"2022-09-28T10:30:37.237426Z","shell.execute_reply.started":"2022-09-28T10:30:37.234010Z"},"trusted":true},"outputs":[],"source":["SIZE = 28\n","\n","PATCH_SIZE = 10\n","\n","OVER_PATCH = 4\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:37.569452Z","iopub.status.busy":"2022-09-28T10:30:37.569050Z","iopub.status.idle":"2022-09-28T10:30:37.574684Z","shell.execute_reply":"2022-09-28T10:30:37.573706Z","shell.execute_reply.started":"2022-09-28T10:30:37.569419Z"},"trusted":true},"outputs":[],"source":["test_vec = x_train[110]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:38.521556Z","iopub.status.busy":"2022-09-28T10:30:38.520851Z","iopub.status.idle":"2022-09-28T10:30:38.736015Z","shell.execute_reply":"2022-09-28T10:30:38.735040Z","shell.execute_reply.started":"2022-09-28T10:30:38.521519Z"},"trusted":true},"outputs":[],"source":["plt.imshow(test_vec)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:38.830129Z","iopub.status.busy":"2022-09-28T10:30:38.829765Z","iopub.status.idle":"2022-09-28T10:30:38.837387Z","shell.execute_reply":"2022-09-28T10:30:38.836226Z","shell.execute_reply.started":"2022-09-28T10:30:38.830097Z"},"trusted":true},"outputs":[],"source":["def patch_creation(image):\n","    '''\n","This function is used to convert an image in the patched version that can be used for the vision transformer.\n","\n","## Inputs:\n","* image: a numpy array of shape (size,size).\n","\n","## Outputs:   \n","* an array of shape ((size/2)**2, 2, 2).\n","\n","note: the size must be an even number.\n","    '''\n","    \n","    out = list()\n","    \n","    size = image.shape[0]\n","    for i in range(int((size-2*OVER_PATCH)/PATCH_SIZE)):\n","        for j in range(int((size-2*OVER_PATCH)/PATCH_SIZE)):\n","            out.append(image[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH, j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH])\n","    return np.array(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:39.117062Z","iopub.status.busy":"2022-09-28T10:30:39.116367Z","iopub.status.idle":"2022-09-28T10:30:39.123782Z","shell.execute_reply":"2022-09-28T10:30:39.122572Z","shell.execute_reply.started":"2022-09-28T10:30:39.117020Z"},"trusted":true},"outputs":[],"source":["patched_example = patch_creation(test_vec)\n","patched_example.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:39.369356Z","iopub.status.busy":"2022-09-28T10:30:39.368971Z","iopub.status.idle":"2022-09-28T10:30:39.544498Z","shell.execute_reply":"2022-09-28T10:30:39.543201Z","shell.execute_reply.started":"2022-09-28T10:30:39.369324Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(nrows=int(SIZE/PATCH_SIZE), ncols=int(SIZE/PATCH_SIZE), figsize=(int(SIZE/PATCH_SIZE),int(SIZE/PATCH_SIZE)))\n","\n","\n","\n","for i in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n","    for j in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n","#         print(f'i: {i}')\n","#         print(f'j: {j}')\n","#         print(f'i*j: {j+ 10*i}')\n","        ax[i,j].imshow(patched_example[j+ int((SIZE-2*OVER_PATCH)/PATCH_SIZE)*i], vmin=0, vmax=0.5)\n","        ax[i,j].axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:39.626019Z","iopub.status.busy":"2022-09-28T10:30:39.625683Z","iopub.status.idle":"2022-09-28T10:30:41.425404Z","shell.execute_reply":"2022-09-28T10:30:41.424361Z","shell.execute_reply.started":"2022-09-28T10:30:39.625989Z"},"trusted":true},"outputs":[],"source":["#this is the most efficent\n","\n","@guvectorize([(float32[:,:,:], float32[:,:,:], float32[:,:,:])],\n","             \"(m, n, n), (m, q, p)->(m, q, p)\", nopython=True)       \n","# note the trick used to ouput a matrix with dimensions q and p, that never appears in the input!\n","# this is probably just a limitation of numba\n","# also note the fact that guvectorize does not have a return! the output arguments has to be the last input! \n","def patch_creation_vec(images, out, out_1):\n","\n","    '''\n","This function is used to convert a set of images in their patched version. This function is vectorized for speed and can be used efficently in the data generator.\n","\n","## Inputs:\n","* images: a numpy array of shape (n_images, size,size).\n","* out_1: output array to be overwritten in the shape (n_images, (size/2)**2, 2, 2).\n","* out: output array to be overwritten in the shape (n_images, (size/2)**2, 2, 2), this second input is needed because the the shapes (size/2)**2 and  4 do not appear in the first array.\n","\n","## Outputs:   \n","* an array of shape (n_images, (size/2)**2, 4).\n","\n","### notes:\n","1) The size must be an even number.\n","2) Since the function uses guvectorize, the output will be returned via in-place modification of the last input argument.\n","\n","    '''\n","\n","\n","    for m in range(images.shape[0]):\n","        c=0\n","        for i in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n","            for j in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n","                # we need to use the ascontiguousarray function in order to be able to reshape the array in numba\n","                out[m, c,:] = np.ascontiguousarray(images[m,\n","                                                          i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n","                                                          j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH])\\\n","                                .reshape((PATCH_SIZE+2*OVER_PATCH)**2)#+1/(c+1)\n","                c+=1 "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:41.427834Z","iopub.status.busy":"2022-09-28T10:30:41.427473Z","iopub.status.idle":"2022-09-28T10:30:41.436562Z","shell.execute_reply":"2022-09-28T10:30:41.435184Z","shell.execute_reply.started":"2022-09-28T10:30:41.427798Z"},"trusted":true},"outputs":[],"source":["def recompose(patched_image):\n","    '''\n","This function is used to recompose an image from its pathced version.\n","\n","## Inputs:\n","* patched_image: a numpy array of shape ((size/2)**2, 4).\n","\n","## Outputs:   \n","* an array of shape (size, size).\n","\n","### notes:\n","1) The size must be an even number.\n","\n","    '''\n","    recomposed = np.zeros(shape=(SIZE,SIZE))\n","    counts = np.zeros(shape=(SIZE,SIZE))\n","\n","    c = 0\n","    for i in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n","        for j in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n","            recomposed[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n","                       j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH] = (patched_image[c].reshape(PATCH_SIZE+2*OVER_PATCH, PATCH_SIZE+2*OVER_PATCH)) + \\\n","                                                                             recomposed[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n","                                                                                        j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH]\n","            c+=1\n","            counts[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n","                       j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH] += 1\n","    \n","    recomposed = recomposed/counts\n","\n","    return recomposed\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:41.439010Z","iopub.status.busy":"2022-09-28T10:30:41.438065Z","iopub.status.idle":"2022-09-28T10:30:41.626898Z","shell.execute_reply":"2022-09-28T10:30:41.625918Z","shell.execute_reply.started":"2022-09-28T10:30:41.438956Z"},"trusted":true},"outputs":[],"source":["plt.imshow(recompose(patched_example))"]},{"cell_type":"markdown","metadata":{},"source":["## reparametrization"]},{"cell_type":"markdown","metadata":{},"source":["$$\\forall i,j  ~~~ N_{i,j} = \\mathcal{N}  $$\n","$$Noised\\_Immage = (\\alpha^n)Immage + N(1-\\alpha^n)$$\n","\n","when:\n","$$n\\rightarrow\\inf \\implies Noised\\_Immage=N$$ \n","$n$ is the number of steps of perturbation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:42.699972Z","iopub.status.busy":"2022-09-28T10:30:42.699284Z","iopub.status.idle":"2022-09-28T10:30:42.707671Z","shell.execute_reply":"2022-09-28T10:30:42.706582Z","shell.execute_reply.started":"2022-09-28T10:30:42.699937Z"},"id":"k21OP-eaU0ZL","trusted":true},"outputs":[],"source":["# n_repeat allows us to present the same image multiple times in the same batch with different type of noise!\n","\n","def add_noise(imm, alpha=0.9, n_max=100, n_repeat=1):\n","        \n","    '''\n","This function is used add the noise to a set of images. The added noise is randomly scaled to correspond to a uniform choice of diffusion step between 0 and n_max.\n","The resulting vector is a set of images with various noise level added.\n","\n","## Inputs:\n","* imm: an numpy array of images. Shape: (n_images, size, size).\n","* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n","* n_max: maximum number of steps of the diffusion process.\n","* n_repeat: if this parameter is different from 1 the same images is used n_repeat to generate noised images.\n","\n","## Outputs:   \n","* noised_image: a numpy array of noised images. Shape: (n_images*n_repeat, size, size). This will be the main input of the ML algorithm.\n","* g_noise_to_add: a numpy array of the added noised, not rescaled by alpha. Shape: (n_images*n_repeat, size, size). This will be the target of the ML algorithm.\n","* array_alphas_n: a numpy array of the used alphas. Shape: (n_images*n_repeat,). This will be part of input of the ML algorithm.\n","    '''\n","    imm = np.tile(imm,(n_repeat,1,1))\n","    shape = imm.shape\n","    g_noise_to_add = np.random.randn(*shape)\n","\n","    array_alphas_n = np.ones(shape[0])*alpha**np.random.randint(0, n_max + 1, shape[0]) \n","\n","    noised_image = np.einsum('i, ikj -> ikj', array_alphas_n,  imm) +\\\n","             np.einsum('i, ikj -> ikj', 1-array_alphas_n,  g_noise_to_add)\n","    return noised_image, g_noise_to_add, array_alphas_n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:43.125475Z","iopub.status.busy":"2022-09-28T10:30:43.124597Z","iopub.status.idle":"2022-09-28T10:30:43.133158Z","shell.execute_reply":"2022-09-28T10:30:43.132149Z","shell.execute_reply.started":"2022-09-28T10:30:43.125429Z"},"trusted":true},"outputs":[],"source":["def add_noise_contolled(imm, alpha=0.9, n=100, n_repeat=1):\n","    '''\n","This function is used add the noise to a set of images. The added noise is scaled to correspond to n-esim step of the diffiusion process.\n","The resulting vector is a set of images with fixed noise level added.\n","\n","## Inputs:\n","* imm: an numpy array of images. Shape: (n_images, size, size).\n","* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n","* n: target step of the diffusion process.\n","* n_repeat: if this parameter is different from 1 the same images is used n_repeat times to generate noised images.\n","\n","## Outputs:   \n","* noised_image: a numpy array of noised images. Shape: (n_images*n_repeat, size, size). This will be the main input of the ML algorithm.\n","* g_noise_to_add: a numpy array of the added noised, not rescaled by alpha. Shape: (n_images*n_repeat, size, size). This will be the target of the ML algorithm.\n","* array_alphas_n: a numpy array of the used alphas. Shape: (n_images*n_repeat,). This will be part of input of the ML algorithm.\n","    '''\n","    imm = np.tile(imm,(n_repeat,1,1))\n","    shape = imm.shape\n","    g_noise_to_add = np.random.randn(*shape)\n","\n","    array_alphas_n = np.ones(shape[0])*alpha**n \n","\n","    noised_image = np.einsum('i, ikj -> ikj', array_alphas_n,  imm) +\\\n","             np.einsum('i, ikj -> ikj', 1-array_alphas_n,  g_noise_to_add)\n","    return noised_image, g_noise_to_add, array_alphas_n"]},{"cell_type":"markdown","metadata":{"id":"uxHd-ilmij_f"},"source":["# creation of the generator"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-09-28T10:30:43.855135Z","iopub.status.busy":"2022-09-28T10:30:43.854772Z","iopub.status.idle":"2022-09-28T10:30:43.869540Z","shell.execute_reply":"2022-09-28T10:30:43.868299Z","shell.execute_reply.started":"2022-09-28T10:30:43.855102Z"},"id":"J8Oc3cD0DFTP","trusted":true},"outputs":[],"source":["class CustomDataGen(tf.keras.utils.Sequence):\n","    \n","    '''\n","This is the main CustomDataGenerator \n","    '''\n","    \n","    \n","    def __init__(self, \n","                 X,\n","                 y,\n","                 batch_size,\n","                 n_repeat=1,\n","                 alpha=0.9,\n","                 n_max=100):\n","            \n","        '''\n","This is the main CustomDataGenerator \n","\n","## Inputs:\n","* X: base dataset\n","* y: label list\n","* batch_size: batch size \n","* n_repeat: if this parameter is different from 1 the same images is used n_repeat times to generate noised images.\n","* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n","* n_max: maximum number of steps of the diffusion process.\n","        '''\n","        \n","        self.X = X\n","        self.y = y\n","        self.batch_size = batch_size\n","        self.n_repeat = n_repeat\n","        self.alpha=alpha\n","        self.n_max=n_max\n","\n","   \n","    def __get_data(self, index):\n","        \n","\n","        noised_imms, random_noise_to_add, alphas_n = add_noise(self.X[index:index+self.batch_size],\n","                                                           n_repeat=self.n_repeat,\n","                                                           alpha=self.alpha,\n","                                                           n_max=self.n_max) \n","\n","#         lables = self.y[index:index+self.batch_size]\n","#         lables = np.tile(lables,(self.n_repeat))\n","        \n","#         lables = (1/(lables+1))\n","        out_noised_imms = np.zeros(shape=(noised_imms.shape[0],\n","                                          int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n","                                          (PATCH_SIZE+2*OVER_PATCH)**2)).astype('float32') \n","        out_random_noise_to_add = np.zeros(shape=(random_noise_to_add.shape[0],\n","                                                  int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n","                                                  (PATCH_SIZE+2*OVER_PATCH)**2)).astype('float32')\n","        noised_imms = noised_imms.astype('float32')\n","        random_noise_to_add = random_noise_to_add.astype('float32')\n","\n","        patched_noised_imm = patch_creation_vec(noised_imms, out_noised_imms, out_noised_imms).reshape(-1,  \n","                                                                                                       int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n","                                                                                                       (PATCH_SIZE+2*OVER_PATCH)**2)\n","        \n","        # we concatenate to the patched images two other information, the used alphas_n and the labels\n","        return (np.concatenate([patched_noised_imm,\n","                                np.einsum('i, ikj -> ikj',\n","                                          alphas_n, \n","                                          np.ones((patched_noised_imm.shape[0],1,patched_noised_imm.shape[2]))),\n","#                                 np.einsum('i, ikj -> ikj',\n","#                                           lables, \n","#                                           np.ones((patched_noised_imm.shape[0],1,patched_noised_imm.shape[2]))),\n","\n","                             ],\n","                             axis=1),\n","              patch_creation_vec(random_noise_to_add, out_random_noise_to_add, out_random_noise_to_add).reshape(-1,  \n","                                                                                                                int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n","                                                                                                                (PATCH_SIZE+2*OVER_PATCH)**2))\n","    \n","    def __getitem__(self, index):\n","\n","        return self.__get_data(index) \n","    \n","    def __len__(self):\n","        return  math.floor(self.X.shape[0]/self.batch_size)\n","    # potrebbe essere necessario presentare molte più versioni del rumore? in fondo queste sono infinitamente facilmente creabili"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:44.165131Z","iopub.status.busy":"2022-09-28T10:30:44.164756Z","iopub.status.idle":"2022-09-28T10:30:44.353054Z","shell.execute_reply":"2022-09-28T10:30:44.351858Z","shell.execute_reply.started":"2022-09-28T10:30:44.165097Z"},"trusted":true},"outputs":[],"source":["#testing generator:\n","\n","gen = CustomDataGen(x_train, y_train, 50)\n","\n","patch_testing = gen.__getitem__(5)[0]\n","\n","plt.imshow(patch_testing[0][3].reshape(PATCH_SIZE+2*OVER_PATCH, PATCH_SIZE+2*OVER_PATCH))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:44.521965Z","iopub.status.busy":"2022-09-28T10:30:44.521274Z","iopub.status.idle":"2022-09-28T10:30:44.528074Z","shell.execute_reply":"2022-09-28T10:30:44.527058Z","shell.execute_reply.started":"2022-09-28T10:30:44.521929Z"},"trusted":true},"outputs":[],"source":["patch_testing.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:44.850231Z","iopub.status.busy":"2022-09-28T10:30:44.849862Z","iopub.status.idle":"2022-09-28T10:30:44.898664Z","shell.execute_reply":"2022-09-28T10:30:44.897672Z","shell.execute_reply.started":"2022-09-28T10:30:44.850199Z"},"trusted":true},"outputs":[],"source":["# creating_val_data\n","ALPHA=0.99\n","N_MAX=500\n","\n","val_gen =  CustomDataGen(x_test, y_test, 800, alpha=ALPHA,  n_max=N_MAX)\n","validation_data = val_gen.__getitem__(1)  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:46.552186Z","iopub.status.busy":"2022-09-28T10:30:46.551789Z","iopub.status.idle":"2022-09-28T10:30:47.067061Z","shell.execute_reply":"2022-09-28T10:30:47.066132Z","shell.execute_reply.started":"2022-09-28T10:30:46.552152Z"},"trusted":true},"outputs":[],"source":["imm = test_vec\n","\n","imm_noised_1, noise1, _ = add_noise_contolled(imm, alpha=ALPHA, n=1)\n","imm_noised_2, noise2, _ = add_noise_contolled(imm, alpha=ALPHA, n=N_MAX)\n","  \n","imm_noised_1 = imm_noised_1.reshape(SIZE, SIZE)\n","imm_noised_2 = imm_noised_2.reshape(SIZE, SIZE)\n","noise1 = noise1.reshape(SIZE,SIZE)\n","noise2 = noise2.reshape(SIZE,SIZE)\n","\n","\n","plt.imshow(np.concatenate([imm_noised_1, imm]))\n","plt.show()\n","plt.imshow(np.concatenate([imm_noised_1, noise1]))\n","plt.show()\n","plt.imshow(np.concatenate([imm_noised_2, noise2]))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:47.069356Z","iopub.status.busy":"2022-09-28T10:30:47.068982Z","iopub.status.idle":"2022-09-28T10:30:47.073767Z","shell.execute_reply":"2022-09-28T10:30:47.072819Z","shell.execute_reply.started":"2022-09-28T10:30:47.069320Z"},"trusted":true},"outputs":[],"source":["ALPHA_N_MAX = ALPHA**N_MAX"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:47.808613Z","iopub.status.busy":"2022-09-28T10:30:47.808206Z","iopub.status.idle":"2022-09-28T10:30:47.815722Z","shell.execute_reply":"2022-09-28T10:30:47.814444Z","shell.execute_reply.started":"2022-09-28T10:30:47.808581Z"},"trusted":true},"outputs":[],"source":["validation_data[0].shape"]},{"cell_type":"markdown","metadata":{},"source":["## "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:48.507027Z","iopub.status.busy":"2022-09-28T10:30:48.506647Z","iopub.status.idle":"2022-09-28T10:30:48.512881Z","shell.execute_reply":"2022-09-28T10:30:48.511368Z","shell.execute_reply.started":"2022-09-28T10:30:48.506993Z"},"trusted":true},"outputs":[],"source":["EPOCH = 200\n","PATIENCE = 5\n","BATCH_SIZE = 5\n","LR = 0.0001\n","N_REPEAT = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:30:49.307330Z","iopub.status.busy":"2022-09-28T10:30:49.306399Z","iopub.status.idle":"2022-09-28T10:30:49.314773Z","shell.execute_reply":"2022-09-28T10:30:49.313690Z","shell.execute_reply.started":"2022-09-28T10:30:49.307278Z"},"trusted":true},"outputs":[],"source":["# this keras layer is used to add a trainable positional enconding to the patches!\n","class PositionPatchEncoder(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super(PositionPatchEncoder, self).__init__()\n","        self.position_embedding = tf.keras.layers.Embedding(input_dim=int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n","                                                            output_dim=(PATCH_SIZE+2*OVER_PATCH)**2)\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2+1, delta=1)\n","        encoded = patch + self.position_embedding(positions)\n","        return encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T10:49:56.998966Z","iopub.status.busy":"2022-09-28T10:49:56.998236Z","iopub.status.idle":"2022-09-28T13:00:21.304442Z","shell.execute_reply":"2022-09-28T13:00:21.302466Z","shell.execute_reply.started":"2022-09-28T10:49:56.998930Z"},"id":"msl-7JV-uaf8","outputId":"fa494944-c855-4d8a-ec80-8c5dc0a513d2","trusted":true},"outputs":[],"source":["\n","def create_model():\n","    \n","    input_tensor = tf.keras.Input(shape=[int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2+1, (PATCH_SIZE+2*OVER_PATCH)**2])\n","\n","    # Adding the positional encoding  \n","    x_start = PositionPatchEncoder()(input_tensor)\n","\n","    # The use of residual connections has been instrumental in the agorithm actualy learning\n","    x_mod = tf.keras.layers.MultiHeadAttention(num_heads=100, key_dim=100)(x_start, x_start)\n","    x = tf.keras.layers.Add()([x_mod, x_start])\n","#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n","#     x = tf.keras.layers.Add()([x_mod, x_start])\n","#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n","#     x = tf.keras.layers.Add()([x_mod, x_start])\n","#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n","#     x = tf.keras.layers.Add()([x_mod, x_start])\n","#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n","#     x = tf.keras.layers.Add()([x_mod, x_start])\n","\n","\n","    \n","    out = tf.keras.layers.Lambda(lambda x: x[:,:int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2])(x)\n","\n","    temp_model = tf.keras.Model(inputs=input_tensor, outputs=out)\n","    \n","    return temp_model\n","\n","gen = CustomDataGen(x_train[:], y_train[:], BATCH_SIZE, alpha=ALPHA,  n_max=N_MAX, n_repeat=N_REPEAT)\n","\n","# Create a new model instance\n","temp_model = create_model()\n","\n","# Restore the weights uncomment and change the model path to use the preloaded model \n","# temp_model.load_weights('../input/diffusion-transformer-multlabel-for-real/model_1')  \n","\n","opt = tf.keras.optimizers.Adam(\n","learning_rate=LR,\n","#clipvalue=1.0\n","\n",")\n","call_stop = tf.keras.callbacks.EarlyStopping(\n","  monitor='val_loss',\n","  patience=PATIENCE,\n","  restore_best_weights=True\n",")\n","temp_model.compile(opt, loss = \"mse\")\n","temp_model.summary()\n","\n","# TRAINING\n","# comment to avoid retraining the model\n","with tf.device('/GPU:0'):\n","    temp_model.fit(gen, epochs=EPOCH, batch_size=BATCH_SIZE, validation_data=validation_data, callbacks=[call_stop])\n","\n","# Save the weights\n","temp_model.save_weights(f'./model_{1}') \n","\n","\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:00:24.063398Z","iopub.status.busy":"2022-09-28T13:00:24.063018Z","iopub.status.idle":"2022-09-28T13:00:24.069150Z","shell.execute_reply":"2022-09-28T13:00:24.068175Z","shell.execute_reply.started":"2022-09-28T13:00:24.063365Z"},"trusted":true},"outputs":[],"source":["def noise_remove(noise, noised_imm, alpha, n=1):\n","    '''\n","This function uses a predicted noise to try and remove the noise. It does can do more step inverse diffusion process in one shoot.\n","\n","## Inputs:\n","* noise: an image of shape (SIZE,SIZE) containining the noise to remove\n","* noised_imm: an image of shape (SIZE,SIZE) image to denoise\n","* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n","* n: number of steps of noise to be removed.\n","\n","## Outputs:   \n","The output is the denoised image\n","    '''\n","\n","    return (noised_imm - noise*(1-alpha**n))/(alpha**n)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:00:29.150992Z","iopub.status.busy":"2022-09-28T13:00:29.150631Z","iopub.status.idle":"2022-09-28T13:00:29.895273Z","shell.execute_reply":"2022-09-28T13:00:29.893313Z","shell.execute_reply.started":"2022-09-28T13:00:29.150962Z"},"trusted":true},"outputs":[],"source":["FIG_N = 2\n","ALPHA=0.9\n","N=1\n","\n","# temp_model = create_model()\n","# temp_model.load_weights(f'./model_{1}')  \n","    \n","fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(15,15))\n","\n","n_imm, noise, _ = add_noise_contolled(x_test[FIG_N], alpha=ALPHA, n=1)\n","\n","n_imm = n_imm.reshape(SIZE,SIZE) \n","noise = noise.reshape(SIZE,SIZE)\n","\n","ax[0][0].imshow(n_imm)\n","ax[0][1].imshow(noise)\n","\n","\n","patched_n_imm = patch_creation(n_imm)\n","print(patched_n_imm.shape)\n","\n","noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n","                                                ALPHA*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n","                                               ], axis=1)).reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n","ax[0][2].imshow(recompose(noise_pred))\n","\n","# # implied image\n","\n","ax[1][0].imshow(noise_remove(recompose(noise_pred),\n","                             n_imm.reshape(SIZE,SIZE),\n","                             alpha=ALPHA))\n","ax[1][1].imshow(noise_remove(recompose(noise_pred),\n","                             n_imm.reshape(SIZE,SIZE),\n","                             alpha=ALPHA,\n","                             n=N))\n","\n","ax[1][2].imshow(x_test[FIG_N].reshape(SIZE,SIZE))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:35:01.196202Z","iopub.status.busy":"2022-09-28T13:35:01.195772Z","iopub.status.idle":"2022-09-28T13:35:01.201738Z","shell.execute_reply":"2022-09-28T13:35:01.200511Z","shell.execute_reply.started":"2022-09-28T13:35:01.196166Z"},"trusted":true},"outputs":[],"source":["N_2 = 50\n","ALPHA2 = (ALPHA_N_MAX)**(1/N_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:35:01.415682Z","iopub.status.busy":"2022-09-28T13:35:01.414836Z","iopub.status.idle":"2022-09-28T13:35:01.421822Z","shell.execute_reply":"2022-09-28T13:35:01.420538Z","shell.execute_reply.started":"2022-09-28T13:35:01.415644Z"},"trusted":true},"outputs":[],"source":["print(N_2)\n","print(ALPHA2)\n","print(ALPHA2**N_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:35:01.671847Z","iopub.status.busy":"2022-09-28T13:35:01.671126Z","iopub.status.idle":"2022-09-28T13:35:04.555153Z","shell.execute_reply":"2022-09-28T13:35:04.554479Z","shell.execute_reply.started":"2022-09-28T13:35:01.671809Z"},"id":"JGc0QhSWjzj_","outputId":"20b073ae-43de-4102-f435-9841584fd86a","trusted":true},"outputs":[],"source":["noised_imm = np.random.randn(SIZE, SIZE) \n","\n","ALPHA = ALPHA2\n","N = N_2\n","STEP = 1\n","print(ALPHA**N)\n","\n","for n in range(N, 0 ,-STEP):\n","    if n%(10*STEP) == 0:\n","        plt.imshow(noised_imm)\n","        plt.show()\n","        print(n)\n","    alpha = (ALPHA)**n\n","    patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n","    noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n","                                                    alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n","                                                   ], axis=1))\\\n","                           .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n","\n","\n","    noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n","             noised_imm.reshape(SIZE,SIZE),\n","             alpha=ALPHA,\n","             n=1.5*STEP)\n","\n","plt.imshow(noised_imm)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:40:36.460691Z","iopub.status.busy":"2022-09-28T13:40:36.459534Z","iopub.status.idle":"2022-09-28T13:41:09.058231Z","shell.execute_reply":"2022-09-28T13:41:09.057198Z","shell.execute_reply.started":"2022-09-28T13:40:36.460652Z"},"trusted":true},"outputs":[],"source":["number = 4\n","\n","fig, ax = plt.subplots(nrows=number, ncols=number, figsize=(20,20))\n","\n","\n","\n","\n","ALPHA = ALPHA2\n","N = N_2\n","STEP = 1\n","print(ALPHA**N)\n","\n","c = 0\n","\n","\n","\n","for i in range(number**2):\n","    print(f'fig n: {i}')\n","    noised_imm = np.random.randn(SIZE, SIZE) #np.concatenate([np.random.randn(SIZE, SIZE)[:,:14], x_test[imm_n][:,14:]], axis=1) # np.random.randn(SIZE, SIZE)#  #\n","    #noised_imm, _ = add_noise(x_test[FIG_N], n=N_STEPS, beta=BETA)\n","\n","    noised_imm = noised_imm.reshape(SIZE,SIZE) \n","    for n in range(N, 0 ,-STEP):\n","        if n%(100*STEP) == 0:\n","            print(n)\n","        alpha = (ALPHA)**n\n","        patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n","        noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n","                                                        alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n","                                                       ], axis=1))\\\n","                               .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n","\n","\n","        noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n","                 noised_imm.reshape(SIZE,SIZE),\n","                 alpha=ALPHA,\n","                 n=STEP)\n","            \n","    ax[int(i/number),i%number].imshow(noised_imm)\n","    ax[int(i/number),i%number].axis('off')\n","\n","    \n","    \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:38:12.834357Z","iopub.status.busy":"2022-09-28T13:38:12.833740Z","iopub.status.idle":"2022-09-28T13:38:43.908216Z","shell.execute_reply":"2022-09-28T13:38:43.907309Z","shell.execute_reply.started":"2022-09-28T13:38:12.834321Z"},"trusted":true},"outputs":[],"source":["number = 4\n","\n","fig, ax = plt.subplots(nrows=number, ncols=number, figsize=(20,20))\n","\n","\n","\n","\n","ALPHA = ALPHA2\n","N = N_2\n","STEP = 1\n","print(ALPHA**N)\n","\n","c = 0\n","\n","\n","\n","for i in range(number**2):\n","    print(f'fig n: {i}')\n","    noised_imm = np.random.randn(SIZE, SIZE) #np.concatenate([np.random.randn(SIZE, SIZE)[:,:14], x_test[imm_n][:,14:]], axis=1) # np.random.randn(SIZE, SIZE)#  #\n","    #noised_imm, _ = add_noise(x_test[FIG_N], n=N_STEPS, beta=BETA)\n","\n","    noised_imm = noised_imm.reshape(SIZE,SIZE) \n","    for n in range(N, 0 ,-STEP):\n","        if n%(100*STEP) == 0:\n","            print(n)\n","        alpha = (ALPHA)**n\n","        patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n","        noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n","                                                        alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n","                                                       ], axis=1))\\\n","                               .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n","\n","\n","        noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n","                 noised_imm.reshape(SIZE,SIZE),\n","                 alpha=ALPHA,\n","                 n=1.5*STEP)\n","            \n","    ax[int(i/number),i%number].imshow(noised_imm)\n","    ax[int(i/number),i%number].axis('off')\n","\n","    \n","    \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-28T13:37:27.950328Z","iopub.status.busy":"2022-09-28T13:37:27.949908Z","iopub.status.idle":"2022-09-28T13:37:55.242090Z","shell.execute_reply":"2022-09-28T13:37:55.241151Z","shell.execute_reply.started":"2022-09-28T13:37:27.950291Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(nrows=25, ncols=20, figsize=(20,20))\n","\n","noised_imm = np.random.randn(SIZE, SIZE) \n","\n","ALPHA = ALPHA2\n","N = N_2\n","STEP = 1\n","print(ALPHA**N)\n","\n","c = 0\n","for n in range(N, 0 ,-STEP):\n","    if n%(100*STEP) == 0:\n","        print(n)\n","    alpha = (ALPHA)**n\n","    patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n","    noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n","                                                    alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n","                                                   ], axis=1))\\\n","                           .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n","\n","\n","    noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n","             noised_imm.reshape(SIZE,SIZE),\n","             alpha=ALPHA,\n","             n=1.5*STEP)\n","    \n","    ax[int(c/20),c%20].imshow(noised_imm)\n","    ax[int(c/20),c%20].axis('off')\n","    c+=1\n","    \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 ('environment': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"1a02df29c0fa5c1dc3096934e738d9ba85babb5f706b02ccf5217a557bdfb2f5"}}},"nbformat":4,"nbformat_minor":4}
