{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport sklearn as sk\n\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior()\n\nfrom skimage.transform import resize\n\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Dense, Input, Flatten,\\\n                                    Reshape, LeakyReLU as LR,\\\n                                    Activation, Dropout, Conv2D, MaxPooling2D, Conv2DTranspose\nfrom tensorflow.keras.models import Model, Sequential\nfrom matplotlib import pyplot as plt\nfrom IPython import display # If using IPython, Colab or Jupyter\nimport numpy as np\nfrom time import time\n\nfrom numba import jit, float32, vectorize, guvectorize\nimport math\n","metadata":{"id":"Q2PepmWUUlzU","execution":{"iopub.status.busy":"2022-09-28T10:29:05.795597Z","iopub.execute_input":"2022-09-28T10:29:05.796437Z","iopub.status.idle":"2022-09-28T10:29:12.587823Z","shell.execute_reply.started":"2022-09-28T10:29:05.796334Z","shell.execute_reply":"2022-09-28T10:29:12.586828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:29:12.590071Z","iopub.execute_input":"2022-09-28T10:29:12.592008Z","iopub.status.idle":"2022-09-28T10:29:14.149687Z","shell.execute_reply.started":"2022-09-28T10:29:12.591966Z","shell.execute_reply":"2022-09-28T10:29:14.148029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n    raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:29:14.154108Z","iopub.execute_input":"2022-09-28T10:29:14.154544Z","iopub.status.idle":"2022-09-28T10:29:16.554958Z","shell.execute_reply.started":"2022-09-28T10:29:14.154503Z","shell.execute_reply":"2022-09-28T10:29:16.553896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"imporing mnist","metadata":{"id":"rj8Ps-_oUqrG"}},{"cell_type":"code","source":"# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nx_train = (x_train/256-0.5).astype('float32') \nx_test = (x_test/256-0.5).astype('float32') ","metadata":{"id":"5wM-J2qfUsQE","execution":{"iopub.status.busy":"2022-09-28T10:29:16.557828Z","iopub.execute_input":"2022-09-28T10:29:16.558441Z","iopub.status.idle":"2022-09-28T10:29:17.531141Z","shell.execute_reply.started":"2022-09-28T10:29:16.558406Z","shell.execute_reply":"2022-09-28T10:29:17.530130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train#[y_train == 2]\nx_test = x_test#[y_test == 2]","metadata":{"id":"ZWZCMLaw6u_p","execution":{"iopub.status.busy":"2022-09-28T10:30:36.979560Z","iopub.execute_input":"2022-09-28T10:30:36.979924Z","iopub.status.idle":"2022-09-28T10:30:36.984459Z","shell.execute_reply.started":"2022-09-28T10:30:36.979895Z","shell.execute_reply":"2022-09-28T10:30:36.983295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 28\n\nPATCH_SIZE = 10\n\nOVER_PATCH = 4\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:37.233346Z","iopub.execute_input":"2022-09-28T10:30:37.234046Z","iopub.status.idle":"2022-09-28T10:30:37.238528Z","shell.execute_reply.started":"2022-09-28T10:30:37.234010Z","shell.execute_reply":"2022-09-28T10:30:37.237426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vec = x_train[110]","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:37.569050Z","iopub.execute_input":"2022-09-28T10:30:37.569452Z","iopub.status.idle":"2022-09-28T10:30:37.574684Z","shell.execute_reply.started":"2022-09-28T10:30:37.569419Z","shell.execute_reply":"2022-09-28T10:30:37.573706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test_vec)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:38.520851Z","iopub.execute_input":"2022-09-28T10:30:38.521556Z","iopub.status.idle":"2022-09-28T10:30:38.736015Z","shell.execute_reply.started":"2022-09-28T10:30:38.521519Z","shell.execute_reply":"2022-09-28T10:30:38.735040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def patch_creation(image):\n    '''\nThis function is used to convert an image in the patched version that can be used for the vision transformer.\n\n## Inputs:\n* image: a numpy array of shape (size,size).\n\n## Outputs:   \n* an array of shape ((size/2)**2, 2, 2).\n\nnote: the size must be an even number.\n    '''\n    \n    out = list()\n    \n    size = image.shape[0]\n    for i in range(int((size-2*OVER_PATCH)/PATCH_SIZE)):\n        for j in range(int((size-2*OVER_PATCH)/PATCH_SIZE)):\n            out.append(image[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH, j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH])\n    return np.array(out)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:38.829765Z","iopub.execute_input":"2022-09-28T10:30:38.830129Z","iopub.status.idle":"2022-09-28T10:30:38.837387Z","shell.execute_reply.started":"2022-09-28T10:30:38.830097Z","shell.execute_reply":"2022-09-28T10:30:38.836226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patched_example = patch_creation(test_vec)\npatched_example.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:39.116367Z","iopub.execute_input":"2022-09-28T10:30:39.117062Z","iopub.status.idle":"2022-09-28T10:30:39.123782Z","shell.execute_reply.started":"2022-09-28T10:30:39.117020Z","shell.execute_reply":"2022-09-28T10:30:39.122572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=int(SIZE/PATCH_SIZE), ncols=int(SIZE/PATCH_SIZE), figsize=(int(SIZE/PATCH_SIZE),int(SIZE/PATCH_SIZE)))\n\n\n\nfor i in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n    for j in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n#         print(f'i: {i}')\n#         print(f'j: {j}')\n#         print(f'i*j: {j+ 10*i}')\n        ax[i,j].imshow(patched_example[j+ int((SIZE-2*OVER_PATCH)/PATCH_SIZE)*i], vmin=0, vmax=0.5)\n        ax[i,j].axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:39.368971Z","iopub.execute_input":"2022-09-28T10:30:39.369356Z","iopub.status.idle":"2022-09-28T10:30:39.544498Z","shell.execute_reply.started":"2022-09-28T10:30:39.369324Z","shell.execute_reply":"2022-09-28T10:30:39.543201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is the most efficent\n\n@guvectorize([(float32[:,:,:], float32[:,:,:], float32[:,:,:])],\n             \"(m, n, n), (m, q, p)->(m, q, p)\", nopython=True)       \n# note the trick used to ouput a matrix with dimensions q and p, that never appears in the input!\n# this is probably just a limitation of numba\n# also note the fact that guvectorize does not have a return! the output arguments has to be the last input! \ndef patch_creation_vec(images, out, out_1):\n\n    '''\nThis function is used to convert a set of images in their patched version. This function is vectorized for speed and can be used efficently in the data generator.\n\n## Inputs:\n* images: a numpy array of shape (n_images, size,size).\n* out_1: output array to be overwritten in the shape (n_images, (size/2)**2, 2, 2).\n* out: output array to be overwritten in the shape (n_images, (size/2)**2, 2, 2), this second input is needed because the the shapes (size/2)**2 and  4 do not appear in the first array.\n\n## Outputs:   \n* an array of shape (n_images, (size/2)**2, 4).\n\n### notes:\n1) The size must be an even number.\n2) Since the function uses guvectorize, the output will be returned via in-place modification of the last input argument.\n\n    '''\n\n\n    for m in range(images.shape[0]):\n        c=0\n        for i in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n            for j in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n                # we need to use the ascontiguousarray function in order to be able to reshape the array in numba\n                out[m, c,:] = np.ascontiguousarray(images[m,\n                                                          i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n                                                          j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH])\\\n                                .reshape((PATCH_SIZE+2*OVER_PATCH)**2)#+1/(c+1)\n                c+=1 ","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:39.625683Z","iopub.execute_input":"2022-09-28T10:30:39.626019Z","iopub.status.idle":"2022-09-28T10:30:41.425404Z","shell.execute_reply.started":"2022-09-28T10:30:39.625989Z","shell.execute_reply":"2022-09-28T10:30:41.424361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recompose(patched_image):\n    '''\nThis function is used to recompose an image from its pathced version.\n\n## Inputs:\n* patched_image: a numpy array of shape ((size/2)**2, 4).\n\n## Outputs:   \n* an array of shape (size, size).\n\n### notes:\n1) The size must be an even number.\n\n    '''\n    recomposed = np.zeros(shape=(SIZE,SIZE))\n    counts = np.zeros(shape=(SIZE,SIZE))\n\n    c = 0\n    for i in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n        for j in range(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)):\n            recomposed[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n                       j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH] = (patched_image[c].reshape(PATCH_SIZE+2*OVER_PATCH, PATCH_SIZE+2*OVER_PATCH)) + \\\n                                                                             recomposed[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n                                                                                        j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH]\n            c+=1\n            counts[i*PATCH_SIZE:i*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH,\n                       j*PATCH_SIZE:j*PATCH_SIZE+PATCH_SIZE+2*OVER_PATCH] += 1\n    \n    recomposed = recomposed/counts\n\n    return recomposed\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:41.427473Z","iopub.execute_input":"2022-09-28T10:30:41.427834Z","iopub.status.idle":"2022-09-28T10:30:41.436562Z","shell.execute_reply.started":"2022-09-28T10:30:41.427798Z","shell.execute_reply":"2022-09-28T10:30:41.435184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(recompose(patched_example))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:41.438065Z","iopub.execute_input":"2022-09-28T10:30:41.439010Z","iopub.status.idle":"2022-09-28T10:30:41.626898Z","shell.execute_reply.started":"2022-09-28T10:30:41.438956Z","shell.execute_reply":"2022-09-28T10:30:41.625918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## reparametrization","metadata":{}},{"cell_type":"markdown","source":"$$\\forall i,j  ~~~ N_{i,j} = \\mathcal{N}  $$\n$$Noised\\_Immage = (\\alpha^n)Immage + N(1-\\alpha^n)$$\n\nwhen:\n$$n\\rightarrow\\inf \\implies Noised\\_Immage=N$$ \n$n$ is the number of steps of perturbation\n","metadata":{}},{"cell_type":"code","source":"# n_repeat allows us to present the same image multiple times in the same batch with different type of noise!\n\ndef add_noise(imm, alpha=0.9, n_max=100, n_repeat=1):\n        \n    '''\nThis function is used add the noise to a set of images. The added noise is randomly scaled to correspond to a uniform choice of diffusion step between 0 and n_max.\nThe resulting vector is a set of images with various noise level added.\n\n## Inputs:\n* imm: an numpy array of images. Shape: (n_images, size, size).\n* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n* n_max: maximum number of steps of the diffusion process.\n* n_repeat: if this parameter is different from 1 the same images is used n_repeat to generate noised images.\n\n## Outputs:   \n* noised_image: a numpy array of noised images. Shape: (n_images*n_repeat, size, size). This will be the main input of the ML algorithm.\n* g_noise_to_add: a numpy array of the added noised, not rescaled by alpha. Shape: (n_images*n_repeat, size, size). This will be the target of the ML algorithm.\n* array_alphas_n: a numpy array of the used alphas. Shape: (n_images*n_repeat,). This will be part of input of the ML algorithm.\n    '''\n    imm = np.tile(imm,(n_repeat,1,1))\n    shape = imm.shape\n    g_noise_to_add = np.random.randn(*shape)\n\n    array_alphas_n = np.ones(shape[0])*alpha**np.random.randint(0, n_max + 1, shape[0]) \n\n    noised_image = np.einsum('i, ikj -> ikj', array_alphas_n,  imm) +\\\n             np.einsum('i, ikj -> ikj', 1-array_alphas_n,  g_noise_to_add)\n    return noised_image, g_noise_to_add, array_alphas_n","metadata":{"id":"k21OP-eaU0ZL","execution":{"iopub.status.busy":"2022-09-28T10:30:42.699284Z","iopub.execute_input":"2022-09-28T10:30:42.699972Z","iopub.status.idle":"2022-09-28T10:30:42.707671Z","shell.execute_reply.started":"2022-09-28T10:30:42.699937Z","shell.execute_reply":"2022-09-28T10:30:42.706582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_noise_contolled(imm, alpha=0.9, n=100, n_repeat=1):\n    '''\nThis function is used add the noise to a set of images. The added noise is scaled to correspond to n-esim step of the diffiusion process.\nThe resulting vector is a set of images with fixed noise level added.\n\n## Inputs:\n* imm: an numpy array of images. Shape: (n_images, size, size).\n* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n* n: target step of the diffusion process.\n* n_repeat: if this parameter is different from 1 the same images is used n_repeat times to generate noised images.\n\n## Outputs:   \n* noised_image: a numpy array of noised images. Shape: (n_images*n_repeat, size, size). This will be the main input of the ML algorithm.\n* g_noise_to_add: a numpy array of the added noised, not rescaled by alpha. Shape: (n_images*n_repeat, size, size). This will be the target of the ML algorithm.\n* array_alphas_n: a numpy array of the used alphas. Shape: (n_images*n_repeat,). This will be part of input of the ML algorithm.\n    '''\n    imm = np.tile(imm,(n_repeat,1,1))\n    shape = imm.shape\n    g_noise_to_add = np.random.randn(*shape)\n\n    array_alphas_n = np.ones(shape[0])*alpha**n \n\n    noised_image = np.einsum('i, ikj -> ikj', array_alphas_n,  imm) +\\\n             np.einsum('i, ikj -> ikj', 1-array_alphas_n,  g_noise_to_add)\n    return noised_image, g_noise_to_add, array_alphas_n","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:43.124597Z","iopub.execute_input":"2022-09-28T10:30:43.125475Z","iopub.status.idle":"2022-09-28T10:30:43.133158Z","shell.execute_reply.started":"2022-09-28T10:30:43.125429Z","shell.execute_reply":"2022-09-28T10:30:43.132149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# creation of the generator","metadata":{"id":"uxHd-ilmij_f"}},{"cell_type":"code","source":"class CustomDataGen(tf.keras.utils.Sequence):\n    \n    '''\nThis is the main CustomDataGenerator \n    '''\n    \n    \n    def __init__(self, \n                 X,\n                 y,\n                 batch_size,\n                 n_repeat=1,\n                 alpha=0.9,\n                 n_max=100):\n            \n        '''\nThis is the main CustomDataGenerator \n\n## Inputs:\n* X: base dataset\n* y: label list\n* batch_size: batch size \n* n_repeat: if this parameter is different from 1 the same images is used n_repeat times to generate noised images.\n* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n* n_max: maximum number of steps of the diffusion process.\n        '''\n        \n        self.X = X\n        self.y = y\n        self.batch_size = batch_size\n        self.n_repeat = n_repeat\n        self.alpha=alpha\n        self.n_max=n_max\n\n   \n    def __get_data(self, index):\n        \n\n        noised_imms, random_noise_to_add, alphas_n = add_noise(self.X[index:index+self.batch_size],\n                                                           n_repeat=self.n_repeat,\n                                                           alpha=self.alpha,\n                                                           n_max=self.n_max) \n\n#         lables = self.y[index:index+self.batch_size]\n#         lables = np.tile(lables,(self.n_repeat))\n        \n#         lables = (1/(lables+1))\n        out_noised_imms = np.zeros(shape=(noised_imms.shape[0],\n                                          int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n                                          (PATCH_SIZE+2*OVER_PATCH)**2)).astype('float32') \n        out_random_noise_to_add = np.zeros(shape=(random_noise_to_add.shape[0],\n                                                  int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n                                                  (PATCH_SIZE+2*OVER_PATCH)**2)).astype('float32')\n        noised_imms = noised_imms.astype('float32')\n        random_noise_to_add = random_noise_to_add.astype('float32')\n\n        patched_noised_imm = patch_creation_vec(noised_imms, out_noised_imms, out_noised_imms).reshape(-1,  \n                                                                                                       int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n                                                                                                       (PATCH_SIZE+2*OVER_PATCH)**2)\n        \n        # we concatenate to the patched images two other information, the used alphas_n and the labels\n        return (np.concatenate([patched_noised_imm,\n                                np.einsum('i, ikj -> ikj',\n                                          alphas_n, \n                                          np.ones((patched_noised_imm.shape[0],1,patched_noised_imm.shape[2]))),\n#                                 np.einsum('i, ikj -> ikj',\n#                                           lables, \n#                                           np.ones((patched_noised_imm.shape[0],1,patched_noised_imm.shape[2]))),\n\n                             ],\n                             axis=1),\n              patch_creation_vec(random_noise_to_add, out_random_noise_to_add, out_random_noise_to_add).reshape(-1,  \n                                                                                                                int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n                                                                                                                (PATCH_SIZE+2*OVER_PATCH)**2))\n    \n    def __getitem__(self, index):\n\n        return self.__get_data(index) \n    \n    def __len__(self):\n        return  math.floor(self.X.shape[0]/self.batch_size)\n    # potrebbe essere necessario presentare molte più versioni del rumore? in fondo queste sono infinitamente facilmente creabili","metadata":{"id":"J8Oc3cD0DFTP","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-09-28T10:30:43.854772Z","iopub.execute_input":"2022-09-28T10:30:43.855135Z","iopub.status.idle":"2022-09-28T10:30:43.869540Z","shell.execute_reply.started":"2022-09-28T10:30:43.855102Z","shell.execute_reply":"2022-09-28T10:30:43.868299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing generator:\n\ngen = CustomDataGen(x_train, y_train, 50)\n\npatch_testing = gen.__getitem__(5)[0]\n\nplt.imshow(patch_testing[0][3].reshape(PATCH_SIZE+2*OVER_PATCH, PATCH_SIZE+2*OVER_PATCH))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:44.164756Z","iopub.execute_input":"2022-09-28T10:30:44.165131Z","iopub.status.idle":"2022-09-28T10:30:44.353054Z","shell.execute_reply.started":"2022-09-28T10:30:44.165097Z","shell.execute_reply":"2022-09-28T10:30:44.351858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patch_testing.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:44.521274Z","iopub.execute_input":"2022-09-28T10:30:44.521965Z","iopub.status.idle":"2022-09-28T10:30:44.528074Z","shell.execute_reply.started":"2022-09-28T10:30:44.521929Z","shell.execute_reply":"2022-09-28T10:30:44.527058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating_val_data\nALPHA=0.99\nN_MAX=500\n\nval_gen =  CustomDataGen(x_test, y_test, 800, alpha=ALPHA,  n_max=N_MAX)\nvalidation_data = val_gen.__getitem__(1)  ","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:44.849862Z","iopub.execute_input":"2022-09-28T10:30:44.850231Z","iopub.status.idle":"2022-09-28T10:30:44.898664Z","shell.execute_reply.started":"2022-09-28T10:30:44.850199Z","shell.execute_reply":"2022-09-28T10:30:44.897672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imm = test_vec\n\nimm_noised_1, noise1, _ = add_noise_contolled(imm, alpha=ALPHA, n=1)\nimm_noised_2, noise2, _ = add_noise_contolled(imm, alpha=ALPHA, n=N_MAX)\n  \nimm_noised_1 = imm_noised_1.reshape(SIZE, SIZE)\nimm_noised_2 = imm_noised_2.reshape(SIZE, SIZE)\nnoise1 = noise1.reshape(SIZE,SIZE)\nnoise2 = noise2.reshape(SIZE,SIZE)\n\n\nplt.imshow(np.concatenate([imm_noised_1, imm]))\nplt.show()\nplt.imshow(np.concatenate([imm_noised_1, noise1]))\nplt.show()\nplt.imshow(np.concatenate([imm_noised_2, noise2]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:46.551789Z","iopub.execute_input":"2022-09-28T10:30:46.552186Z","iopub.status.idle":"2022-09-28T10:30:47.067061Z","shell.execute_reply.started":"2022-09-28T10:30:46.552152Z","shell.execute_reply":"2022-09-28T10:30:47.066132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ALPHA_N_MAX = ALPHA**N_MAX","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:47.068982Z","iopub.execute_input":"2022-09-28T10:30:47.069356Z","iopub.status.idle":"2022-09-28T10:30:47.073767Z","shell.execute_reply.started":"2022-09-28T10:30:47.069320Z","shell.execute_reply":"2022-09-28T10:30:47.072819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:47.808206Z","iopub.execute_input":"2022-09-28T10:30:47.808613Z","iopub.status.idle":"2022-09-28T10:30:47.815722Z","shell.execute_reply.started":"2022-09-28T10:30:47.808581Z","shell.execute_reply":"2022-09-28T10:30:47.814444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"EPOCH = 200\nPATIENCE = 5\nBATCH_SIZE = 5\nLR = 0.0001\nN_REPEAT = 100","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:48.506647Z","iopub.execute_input":"2022-09-28T10:30:48.507027Z","iopub.status.idle":"2022-09-28T10:30:48.512881Z","shell.execute_reply.started":"2022-09-28T10:30:48.506993Z","shell.execute_reply":"2022-09-28T10:30:48.511368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this keras layer is used to add a trainable positional enconding to the patches!\nclass PositionPatchEncoder(tf.keras.layers.Layer):\n    def __init__(self):\n        super(PositionPatchEncoder, self).__init__()\n        self.position_embedding = tf.keras.layers.Embedding(input_dim=int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2,\n                                                            output_dim=(PATCH_SIZE+2*OVER_PATCH)**2)\n\n    def call(self, patch):\n        positions = tf.range(start=0, limit=int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2+1, delta=1)\n        encoded = patch + self.position_embedding(positions)\n        return encoded","metadata":{"execution":{"iopub.status.busy":"2022-09-28T10:30:49.306399Z","iopub.execute_input":"2022-09-28T10:30:49.307330Z","iopub.status.idle":"2022-09-28T10:30:49.314773Z","shell.execute_reply.started":"2022-09-28T10:30:49.307278Z","shell.execute_reply":"2022-09-28T10:30:49.313690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef create_model():\n    \n    input_tensor = tf.keras.Input(shape=[int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2+1, (PATCH_SIZE+2*OVER_PATCH)**2])\n\n    # Adding the positional encoding  \n    x_start = PositionPatchEncoder()(input_tensor)\n\n    # The use of residual connections has been instrumental in the agorithm actualy learning\n    x_mod = tf.keras.layers.MultiHeadAttention(num_heads=100, key_dim=100)(x_start, x_start)\n    x = tf.keras.layers.Add()([x_mod, x_start])\n#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n#     x = tf.keras.layers.Add()([x_mod, x_start])\n#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n#     x = tf.keras.layers.Add()([x_mod, x_start])\n#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n#     x = tf.keras.layers.Add()([x_mod, x_start])\n#     x_mod = tf.keras.layers.MultiHeadAttention(num_heads=10, key_dim=100)(x, x)\n#     x = tf.keras.layers.Add()([x_mod, x_start])\n\n\n    \n    out = tf.keras.layers.Lambda(lambda x: x[:,:int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2])(x)\n\n    temp_model = tf.keras.Model(inputs=input_tensor, outputs=out)\n    \n    return temp_model\n\ngen = CustomDataGen(x_train[:], y_train[:], BATCH_SIZE, alpha=ALPHA,  n_max=N_MAX, n_repeat=N_REPEAT)\n\n# Create a new model instance\ntemp_model = create_model()\n\n# Restore the weights uncomment and change the model path to use the preloaded model \n# temp_model.load_weights('../input/diffusion-transformer-multlabel-for-real/model_1')  \n\nopt = tf.keras.optimizers.Adam(\nlearning_rate=LR,\n#clipvalue=1.0\n\n)\ncall_stop = tf.keras.callbacks.EarlyStopping(\n  monitor='val_loss',\n  patience=PATIENCE,\n  restore_best_weights=True\n)\ntemp_model.compile(opt, loss = \"mse\")\ntemp_model.summary()\n\n# TRAINING\n# comment to avoid retraining the model\nwith tf.device('/GPU:0'):\n    temp_model.fit(gen, epochs=EPOCH, batch_size=BATCH_SIZE, validation_data=validation_data, callbacks=[call_stop])\n\n# Save the weights\ntemp_model.save_weights(f'./model_{1}') \n\n\n\n    ","metadata":{"id":"msl-7JV-uaf8","outputId":"fa494944-c855-4d8a-ec80-8c5dc0a513d2","execution":{"iopub.status.busy":"2022-09-28T10:49:56.998236Z","iopub.execute_input":"2022-09-28T10:49:56.998966Z","iopub.status.idle":"2022-09-28T13:00:21.304442Z","shell.execute_reply.started":"2022-09-28T10:49:56.998930Z","shell.execute_reply":"2022-09-28T13:00:21.302466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def noise_remove(noise, noised_imm, alpha, n=1):\n    '''\nThis function uses a predicted noise to try and remove the noise. It does can do more step inverse diffusion process in one shoot.\n\n## Inputs:\n* noise: an image of shape (SIZE,SIZE) containining the noise to remove\n* noised_imm: an image of shape (SIZE,SIZE) image to denoise\n* alpha: scaling of the noise to add in one step. The more alpha is close to one the less noise is added at every step of the diffusion process.\n* n: number of steps of noise to be removed.\n\n## Outputs:   \nThe output is the denoised image\n    '''\n\n    return (noised_imm - noise*(1-alpha**n))/(alpha**n)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T13:00:24.063018Z","iopub.execute_input":"2022-09-28T13:00:24.063398Z","iopub.status.idle":"2022-09-28T13:00:24.069150Z","shell.execute_reply.started":"2022-09-28T13:00:24.063365Z","shell.execute_reply":"2022-09-28T13:00:24.068175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FIG_N = 2\nALPHA=0.9\nN=1\n\n# temp_model = create_model()\n# temp_model.load_weights(f'./model_{1}')  \n    \nfig, ax = plt.subplots(nrows=2, ncols=3, figsize=(15,15))\n\nn_imm, noise, _ = add_noise_contolled(x_test[FIG_N], alpha=ALPHA, n=1)\n\nn_imm = n_imm.reshape(SIZE,SIZE) \nnoise = noise.reshape(SIZE,SIZE)\n\nax[0][0].imshow(n_imm)\nax[0][1].imshow(noise)\n\n\npatched_n_imm = patch_creation(n_imm)\nprint(patched_n_imm.shape)\n\nnoise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n                                                ALPHA*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n                                               ], axis=1)).reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\nax[0][2].imshow(recompose(noise_pred))\n\n# # implied image\n\nax[1][0].imshow(noise_remove(recompose(noise_pred),\n                             n_imm.reshape(SIZE,SIZE),\n                             alpha=ALPHA))\nax[1][1].imshow(noise_remove(recompose(noise_pred),\n                             n_imm.reshape(SIZE,SIZE),\n                             alpha=ALPHA,\n                             n=N))\n\nax[1][2].imshow(x_test[FIG_N].reshape(SIZE,SIZE))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T13:00:29.150631Z","iopub.execute_input":"2022-09-28T13:00:29.150992Z","iopub.status.idle":"2022-09-28T13:00:29.895273Z","shell.execute_reply.started":"2022-09-28T13:00:29.150962Z","shell.execute_reply":"2022-09-28T13:00:29.893313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_2 = 50\nALPHA2 = (ALPHA_N_MAX)**(1/N_2)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T13:35:01.195772Z","iopub.execute_input":"2022-09-28T13:35:01.196202Z","iopub.status.idle":"2022-09-28T13:35:01.201738Z","shell.execute_reply.started":"2022-09-28T13:35:01.196166Z","shell.execute_reply":"2022-09-28T13:35:01.200511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(N_2)\nprint(ALPHA2)\nprint(ALPHA2**N_2)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T13:35:01.414836Z","iopub.execute_input":"2022-09-28T13:35:01.415682Z","iopub.status.idle":"2022-09-28T13:35:01.421822Z","shell.execute_reply.started":"2022-09-28T13:35:01.415644Z","shell.execute_reply":"2022-09-28T13:35:01.420538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noised_imm = np.random.randn(SIZE, SIZE) \n\nALPHA = ALPHA2\nN = N_2\nSTEP = 1\nprint(ALPHA**N)\n\nfor n in range(N, 0 ,-STEP):\n    if n%(10*STEP) == 0:\n        plt.imshow(noised_imm)\n        plt.show()\n        print(n)\n    alpha = (ALPHA)**n\n    patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n    noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n                                                    alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n                                                   ], axis=1))\\\n                           .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n\n\n    noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n             noised_imm.reshape(SIZE,SIZE),\n             alpha=ALPHA,\n             n=1.5*STEP)\n\nplt.imshow(noised_imm)\nplt.show()","metadata":{"id":"JGc0QhSWjzj_","outputId":"20b073ae-43de-4102-f435-9841584fd86a","execution":{"iopub.status.busy":"2022-09-28T13:35:01.671126Z","iopub.execute_input":"2022-09-28T13:35:01.671847Z","iopub.status.idle":"2022-09-28T13:35:04.555153Z","shell.execute_reply.started":"2022-09-28T13:35:01.671809Z","shell.execute_reply":"2022-09-28T13:35:04.554479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 4\n\nfig, ax = plt.subplots(nrows=number, ncols=number, figsize=(20,20))\n\n\n\n\nALPHA = ALPHA2\nN = N_2\nSTEP = 1\nprint(ALPHA**N)\n\nc = 0\n\n\n\nfor i in range(number**2):\n    print(f'fig n: {i}')\n    noised_imm = np.random.randn(SIZE, SIZE) #np.concatenate([np.random.randn(SIZE, SIZE)[:,:14], x_test[imm_n][:,14:]], axis=1) # np.random.randn(SIZE, SIZE)#  #\n    #noised_imm, _ = add_noise(x_test[FIG_N], n=N_STEPS, beta=BETA)\n\n    noised_imm = noised_imm.reshape(SIZE,SIZE) \n    for n in range(N, 0 ,-STEP):\n        if n%(100*STEP) == 0:\n            print(n)\n        alpha = (ALPHA)**n\n        patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n        noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n                                                        alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n                                                       ], axis=1))\\\n                               .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n\n\n        noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n                 noised_imm.reshape(SIZE,SIZE),\n                 alpha=ALPHA,\n                 n=STEP)\n            \n    ax[int(i/number),i%number].imshow(noised_imm)\n    ax[int(i/number),i%number].axis('off')\n\n    \n    \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T13:40:36.459534Z","iopub.execute_input":"2022-09-28T13:40:36.460691Z","iopub.status.idle":"2022-09-28T13:41:09.058231Z","shell.execute_reply.started":"2022-09-28T13:40:36.460652Z","shell.execute_reply":"2022-09-28T13:41:09.057198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 4\n\nfig, ax = plt.subplots(nrows=number, ncols=number, figsize=(20,20))\n\n\n\n\nALPHA = ALPHA2\nN = N_2\nSTEP = 1\nprint(ALPHA**N)\n\nc = 0\n\n\n\nfor i in range(number**2):\n    print(f'fig n: {i}')\n    noised_imm = np.random.randn(SIZE, SIZE) #np.concatenate([np.random.randn(SIZE, SIZE)[:,:14], x_test[imm_n][:,14:]], axis=1) # np.random.randn(SIZE, SIZE)#  #\n    #noised_imm, _ = add_noise(x_test[FIG_N], n=N_STEPS, beta=BETA)\n\n    noised_imm = noised_imm.reshape(SIZE,SIZE) \n    for n in range(N, 0 ,-STEP):\n        if n%(100*STEP) == 0:\n            print(n)\n        alpha = (ALPHA)**n\n        patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n        noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n                                                        alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n                                                       ], axis=1))\\\n                               .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n\n\n        noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n                 noised_imm.reshape(SIZE,SIZE),\n                 alpha=ALPHA,\n                 n=1.5*STEP)\n            \n    ax[int(i/number),i%number].imshow(noised_imm)\n    ax[int(i/number),i%number].axis('off')\n\n    \n    \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T13:38:12.833740Z","iopub.execute_input":"2022-09-28T13:38:12.834357Z","iopub.status.idle":"2022-09-28T13:38:43.908216Z","shell.execute_reply.started":"2022-09-28T13:38:12.834321Z","shell.execute_reply":"2022-09-28T13:38:43.907309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=25, ncols=20, figsize=(20,20))\n\nnoised_imm = np.random.randn(SIZE, SIZE) \n\nALPHA = ALPHA2\nN = N_2\nSTEP = 1\nprint(ALPHA**N)\n\nc = 0\nfor n in range(N, 0 ,-STEP):\n    if n%(100*STEP) == 0:\n        print(n)\n    alpha = (ALPHA)**n\n    patched_n_imm = patch_creation(noised_imm.reshape(SIZE,SIZE))\n    noise_pred = temp_model.predict(np.concatenate([patched_n_imm.reshape(1, patched_n_imm.shape[0], (PATCH_SIZE+2*OVER_PATCH)**2),\n                                                    alpha*np.ones((1,1,(PATCH_SIZE+2*OVER_PATCH)**2))\n                                                   ], axis=1))\\\n                           .reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)\n\n\n    noised_imm = noise_remove(recompose(noise_pred.reshape(int((SIZE-2*OVER_PATCH)/PATCH_SIZE)**2, (PATCH_SIZE+2*OVER_PATCH)**2)),\n             noised_imm.reshape(SIZE,SIZE),\n             alpha=ALPHA,\n             n=1.5*STEP)\n    \n    ax[int(c/20),c%20].imshow(noised_imm)\n    ax[int(c/20),c%20].axis('off')\n    c+=1\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T13:37:27.949908Z","iopub.execute_input":"2022-09-28T13:37:27.950328Z","iopub.status.idle":"2022-09-28T13:37:55.242090Z","shell.execute_reply.started":"2022-09-28T13:37:27.950291Z","shell.execute_reply":"2022-09-28T13:37:55.241151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}